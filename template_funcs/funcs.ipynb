{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28fdfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as datetime\n",
    "import time\n",
    "import shap\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit, cross_validate, train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, confusion_matrix, classification_report,ConfusionMatrixDisplay\n",
    "import xgboost as xgb\n",
    "from pandas_profiling import ProfileReport\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import sys\n",
    "from sklearn.experimental import enable_iterative_imputer \n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import os\n",
    "\n",
    "\n",
    "pd.options.display.max_rows = 2000\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff6562d",
   "metadata": {},
   "source": [
    "# Eda Functions and running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96920fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttest(df,target, feature):\n",
    "    pos_class = df[df[target]==1][feature]\n",
    "    neg_class = df[df[target]==0][feature]\n",
    "    tstat, pval = stats.ttest_ind(pos_class, neg_class, equal_var=False)\n",
    "    print('t-statistic: {:.1f}, p-value: {:.3}'.format(tstat, pval))\n",
    "    \n",
    "def describe_cont_feature(df,target,feature):\n",
    "    print('\\n*** Results for {} ***'.format(feature))\n",
    "    print(df.groupby(target)[feature].describe())\n",
    "    print(ttest(df, target, feature))\n",
    "\n",
    "def quad_plot(df, feature, target, logistic = True):\n",
    "    f, axes = plt.subplots(2, 2,figsize=(15,15))\n",
    "    # top left swarm with boxplot\n",
    "    sns.boxplot(x=df[target], y=df[feature], palette = \"viridis\", ax = axes[0][0])\n",
    "    sns.violinplot(x=df[target], y=df[feature], color=\"turquoise\", ax = axes[0][0])\n",
    "    plt.setp(axes[0][0].collections, alpha=.3)\n",
    "    # top right cumulative density plot\n",
    "    sns.kdeplot(data = df, x = feature, hue = target, palette= \"viridis_r\", multiple = \"fill\", ax = axes[0][1])\n",
    "    axes[0][1].legend([target,\"Not {}\".format(target)])\n",
    "    if (df[feature].min() > 0):\n",
    "        axes[0][1].set_xlim(left = 0)\n",
    "    # bottom left regression plot either logistic or regular\n",
    "    if logistic == False:\n",
    "        sns.regplot(data = df, x= feature,y= target,logistic = False,color = 'teal', ax = axes[1][0])\n",
    "    else:\n",
    "        sns.regplot(data = df, x= feature,y= target,logistic = True,color = 'teal', ax = axes[1][0])\n",
    "    # bottom right is are comparing the distributions of the features between positive and negative class\n",
    "    sns.distplot(df.loc[df[target] != 1,feature], color = 'teal', ax = axes[1][1])\n",
    "    sns.distplot(df.loc[df[target] == 1,feature], color = 'purple', ax = axes[1][1])\n",
    "    if (df[feature].min() > 0):\n",
    "        axes[1][1].set_xlim(left = 0)\n",
    "    plt.show()\n",
    "    \n",
    "def univariate_breakdown(df, feature, target, logistic = True):\n",
    "    \n",
    "    describe_cont_feature(df,target,feature)\n",
    "    quad_plot(df, feature, target, logistic = logistic)\n",
    "\n",
    "def cols_analysis(df, target, ignore_cols = []):\n",
    "    continuous_cols = [col for col in df.columns if col not in ignore_cols]\n",
    "    for col in continuous_cols:\n",
    "        print(\"Pearson correlation of {} to target {}: {}\"\n",
    "              .format(col, target, df[col].corr(df[target])))\n",
    "        univariate_breakdown(df, col ,target)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873561bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# continuous variable EDA\n",
    "# specify continuous columns\n",
    "cont_cols = []\n",
    "cols_analysis(df= model_df[cont_cols], target = 'not_working', ignore_cols = ['UnitID','not_working','dow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a57f0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_barplot(df, target, feat2):\n",
    "    plt.figure(figsize = (12,8))\n",
    "    sns.barplot(y = df[feat1], x = df[feat2], palette = \"viridis\", orient = \"h\")\n",
    "    plt.show()\n",
    "# Categorical variable EDA\n",
    "# for col in categorical colsumns:\n",
    "    univariate_barplot(model_df, target = '', feature = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5e066f",
   "metadata": {},
   "source": [
    "# Modeling Funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "9db0c6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_holdout(model_df,target, split = 0.3, validation_set = False, categorical_cols = []):\n",
    "    # randomize data \n",
    "    model_df = model_df.sample(frac=1, random_state = 33).reset_index(drop=True)\n",
    "    X = model_df.copy()\n",
    "    if len(categorical_cols) > 0:\n",
    "        X = pd.get_dummies(model_df, drop_first = True, columns = categorical_cols)\n",
    "    y = model_df[[target]].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= split, random_state= 33 )\n",
    "    # for holdout set take piece of train i.e. 0.125 x 0.8 = 0.1 of whole set\n",
    "    if validation_set == True:\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state= 33 ) \n",
    "    target_weight = (len(y_train) - y_train[:,0].sum()) / y_train[:,0].sum()\n",
    "    if validation_set == True:\n",
    "        return X_train, y_train, X_test, y_test, X_val, y_val, target_weight\n",
    "    return X_train, y_train, X_test, y_test, target_weight\n",
    "\n",
    "def reg_imputer(X_train, X_test, X_val = None, drop_cols = []):\n",
    "    # if iterative imputer is throwing errors because it is imputing impossibly large values,\n",
    "    # use min_vale = __ and max_value = ___ as parameters when initializing class object\n",
    "    imp_reg = IterativeImputer(random_state=0)\n",
    "    x_cols = [col for col in X_train if col not in drop_cols]\n",
    "    X_train_reg = pd.DataFrame(imp_reg.fit_transform(X_train.drop(columns =  drop_cols)), columns =x_cols)\n",
    "    X_train_reg.loc[:,drop_cols] =  X_train[drop_cols].reset_index(drop = True).copy()\n",
    "    X_test_reg = pd.DataFrame(imp_reg.transform(X_test.drop(columns =  drop_cols)), columns =x_cols)\n",
    "    X_test_reg.loc[:,drop_cols] =  X_test[drop_cols].reset_index(drop = True).copy()\n",
    "    if (X_val is not None):\n",
    "        X_val_reg = pd.DataFrame(imp_reg.transform(X_val.drop(columns =  drop_cols)), columns =x_cols)\n",
    "        X_val_reg.loc[:,drop_cols] =  X_val[drop_cols].reset_index(drop = True).copy()\n",
    "    return X_train_reg, X_test_reg, X_val_reg\n",
    "    \n",
    "def model_summary(model, X_train, y_train, X_test, y_test, threshold = 0.5):\n",
    "    # train set predictions\n",
    "    train_pred_prob = model.predict_proba(X_train)[:,1]\n",
    "    train_pred = (train_pred_prob > threshold).astype(\"int\")\n",
    "    # test set predictions\n",
    "    test_pred_prob = model.predict_proba(X_test)[:,1]\n",
    "    test_pred = (test_pred_prob > threshold).astype(\"int\")\n",
    "    # model report\n",
    "    print(\"Confusion Matrix for Test Set\")\n",
    "    print(confusion_matrix(y_test, test_pred))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix(y_test, test_pred))\n",
    "    disp.plot()\n",
    "    \n",
    "    print(\"\\n Classification Report for Test Set\")\n",
    "    print(classification_report(y_test, test_pred))\n",
    "    \n",
    "    print(\"Accuracy Train: {:.4f}\".format(accuracy_score(y_train, train_pred)))\n",
    "    print(\"AUC Train: {}\".format(roc_auc_score(y_train, train_pred)))\n",
    "    print(\"Accuracy Test: {:.4f}\".format(accuracy_score(y_test, test_pred)))\n",
    "    print(\"AUC Test: {}\".format(roc_auc_score(y_test, test_pred)))\n",
    "    \n",
    "def plot_roc_curve(model, X_test, y_test):\n",
    "    y_pred = model.predict_proba(X_test)[:,1]\n",
    "    y_pred_pred = model.predict(X_test)\n",
    "    test_auc = roc_auc_score(y_test, y_pred_pred)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label = \"AUC = {:.3f}\".format(test_auc))\n",
    "    plt.plot([0,1],[0,1],'r--')\n",
    "    plt.xlim([0,1])\n",
    "    plt.ylim([0,1.05])\n",
    "    plt.title(\"ROC Plot\")\n",
    "    plt.legend(loc = \"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "f80b5a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ''\n",
    "# add anything else here\n",
    "drop_cols = [target] + []\n",
    "X_train, y_train, X_test, y_test, X_val, y_val, target_weight = get_train_test_holdout(model_df,\n",
    "                                                                                       target,\n",
    "                                                                                       split = 0.2,\n",
    "                                                                                       validation_set = True,\n",
    "                                                                                       cat_cols = [])\n",
    "# impute nulls\n",
    "X_train_reg, X_test_reg, X_val_reg = reg_imputer(X_train, X_test, X_val, drop_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96ebc9d",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf1bd2c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(X_train_reg.drop(columns =drop_cols), y_train)\n",
    "log_pred_prob = clf.predict_proba(X_test_reg.drop(columns = drop_cols))[:,1]\n",
    "log_pred = clf.predict(X_test_reg.drop(columns = drop_cols))\n",
    "\n",
    "print(\"Logistic Regression Result\")\n",
    "model_summary(clf, X_train_reg.drop(columns = drop_cols), y_train,\n",
    "              X_test_reg.drop(columns = drop_cols), y_test)\n",
    "plot_roc_curve(clf, X_test_reg.drop(columns = drop_cols), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85e9423",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2eac49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline XGB \n",
    "seed = 30\n",
    "simple_xgb = xgb.XGBClassifier(random_state = seed, scale_pos_weight = target_weight)\n",
    "simple_xgb.fit(X_train.drop(columns = drop_cols), y_train)\n",
    "simple_xgb_pred_prob = simple_xgb.predict_proba(X_test.drop(columns = drop_cols))[:,1]\n",
    "simple_xgb_pred = simple_xgb.predict(X_test.drop(columns = drop_cols))\n",
    "\n",
    "print(\"Simple XGBoost Result\")\n",
    "model_summary(simple_xgb, X_train.drop(columns = drop_cols), y_train,\n",
    "              X_test.drop(columns = drop_cols), y_test)\n",
    "plot_roc_curve(simple_xgb, X_test.drop(columns = drop_cols), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476e369a",
   "metadata": {},
   "source": [
    "# Validation Set results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4c477b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# holdout set results\n",
    "val_pred = simple_xgb.predict(X_val.drop(columns = drop_cols))\n",
    "val_pred_proba = simple_xgb.predict_proba(X_val.drop(columns = drop_cols))[:,1]\n",
    "\n",
    "model_summary(simple_xgb, X_train.drop(columns = drop_cols), y_train,\n",
    "              X_val.drop(columns = drop_cols), y_val)\n",
    "plot_roc_curve(simple_xgb, X_val.drop(columns = drop_cols), y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94598d9d",
   "metadata": {},
   "source": [
    "# Shap Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af563b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap results for model\n",
    "mybooster = simple_xgb.get_booster()\n",
    "model_bytearray = mybooster.save_raw()[4:]\n",
    "def myfunc(self = None):\n",
    "    return model_bytearray\n",
    "mybooster.save_raw = myfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d50e63",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(mybooster)\n",
    "simple_shap_values = explainer.shap_values(X_test.drop(columns = drop_cols))\n",
    "shap.summary_plot(simple_shap_values, X_test.drop(columns = drop_cols), \n",
    "                  max_display = X_test.drop(columns = drop_cols).columns.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611297c0",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0bf153",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7abf68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_X = StandardScaler()\n",
    "X_train_std = sc_X.fir_transform(X_train)\n",
    "X_test_std = sc_X.transform(X_test)\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train_std, y_train)\n",
    "coef = regressor.coef_\n",
    "y_pred = regressor.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe42746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# residuals\n",
    "sns.residplot(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ba8da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = xgb.XGBRegressor(objective = 'reg:linear')\n",
    "eval_set = [(xtrain y train), (xtest y tesm)]\n",
    "model.fit(xrrain, ytrain, evalset = evalset, eval_metric =' mae', early stopping rounds =30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
